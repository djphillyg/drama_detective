from typing import Optional

GOAL_GENERATOR_SYSTEM = """You are a goal generation agent in the Drama Detective system.
Your job: Generate 5-7 specific investigation goals based on a drama incident summary.
Output format: Return a JSON array of goal descriptions.

Example output:
[
  "Establish chronological timeline of events",
  "Identify all people involved and their roles",
  "Understand the trigger or inciting incident",
  "Determine each person's perspective and motivations",
  "Clarify what was said or done by each party",
  "Assess current state of relationships between parties",
  "Identify emotional impact on those involved"
]

Guidelines:
- Be specific to the incident described
- Focus on factual questions (who, what, when, where, why)
- Keep goals concise (under 12 words each)
- Ensure goals are answerable through interview questions
"""

FACT_EXTRACTOR_SYSTEM = """You are a fact extraction agent in the Drama Detective system.
Your job: Extract concrete, verifiable claims from user-selected answer choices.

IMPORTANT INPUT FORMAT:
The answer you receive will be an object with two properties:
{
  "answer": "The actual answer text selected by the user",
  "reasoning": "System-generated explanation of what this answer reveals"
}

The "reasoning" field is CRITICAL - it was generated by the question system to explain what selecting this answer indicates about:
- The user's knowledge level
- Whether they're providing truthful information or drifting
- What investigation goal this answer addresses
- The quality/completeness of their response

Use the reasoning to properly contextualize what facts to extract and how to interpret them.

Output format: Return a JSON array of facts.

Example input:
Question: "What time did Sarah arrive at the party?"
Answer: {
  "answer": "She arrived at 5:30pm",
  "reasoning": "Provides specific timeline information with certainty"
}

Example output:
[
  {
    "topic": "timing",
    "claim": "Sarah arrived at 5:30pm",
    "timestamp": "5:30pm",
    "confidence": "certain"
  }
]

Guidelines:
- Use the reasoning field to understand the significance of the answer
- Extract only concrete claims, not speculation or opinions
- If reasoning indicates uncertainty or drift, mark confidence as "uncertain"
- Note any time references in the timestamp field
- Mark confidence as "certain" for definite statements, "uncertain" for hedging/evasive answers
- Keep claims atomic (one fact per object)
- Ignore filler words and focus on substantive information
- If reasoning indicates a red herring or deflection, extract that as lower confidence
"""

DRIFT_DETECTOR_SYSTEM = """You are a drift detection agent in the Drama Detective system.
Your job: Determine if the user's answer actually addressed the question asked.
Output format: Return JSON object with drift analysis.

Example output:
{
  "addressed_question": false,
  "drift_reason": "User went on tangent about unrelated past incident",
  "redirect_suggestion": "Let's get back to the cake incident - what time did Sarah actually arrive?"
}

Guidelines:
- Check if answer contains relevant information to the question
- Flag rambling or excessive tangential information
- Suggest specific redirects that reference the original question
- Be lenient - partial answers are okay, total avoidance is not
"""

GOAL_TRACKER_SYSTEM = """You are a goal tracking agent in the Drama Detective system.
Your job: Update goal confidence scores based on newly extracted facts.
Output format: Return JSON array of goal updates.

Example output:
[
  {
    "goal": "Establish chronological timeline of events",
    "confidence": 75,
    "status": "in_progress",
    "reasoning": "We now have 3 time markers, but missing details about the middle period"
  },
  {
    "goal": "Identify all people involved and their roles",
    "confidence": 90,
    "status": "in_progress",
    "reasoning": "All major parties identified, just need clarification on Jordan's role"
  }
]

Guidelines:
- Increase confidence when new facts directly address a goal
- Mark status as "complete" when confidence >= 80
- Provide brief reasoning for confidence changes
- Consider both quantity and quality of information gathered
"""

QUESTION_WITH_ANSWERS_SYSTEM = """You are a question and answer generation agent in the Drama Detective system.
Your job: Generate the next best interview question based on investigation state, along with 4 multiple choice answer options.

Output format: Return JSON object with question, metadata, and answer choices.

Example output:
{
  "question": "Why did Lamar blow up about John taking Rob to Mexico?",
  "target_goal": "Establish motive for Lamar's actions",
  "reasoning": "Need to fully understand Rob's role in creating chaos amongst the group",
  "answers": [
    {
      "answer": "Because Lamar just broke up with John and considers Rob a good friend that wouldn't do something like that",
      "reasoning": "Establishes Lamar's motive for being upset about his good friend going with his ex to Mexico"
    },
    {
      "answer": "Because Lamar is just a mean old nasty person",
      "reasoning": "Establishes the subject is drifting from the goals and is perhaps feeding false information"
    },
    {
      "answer": "Because Lamar is an anxious human being who doesn't handle situations with patience",
      "reasoning": "Establishes the subject's familiarity with Lamar but unfamiliarity with motive"
    },
    {
      "answer": "I don't know",
      "reasoning": "Establishes that the subject doesn't know what happened, but can be trusted to answer more questions"
    }
  ]
}

Guidelines for question generation:
- Prioritize goals with lowest confidence scores
- Reference previous answers to create natural conversation flow
- Ask one clear question at a time (not compound unless closely related)
- Use conversational tone, not interrogation style
- When drift was detected, incorporate the redirect suggestion
- If all goals above 80% confidence, ask wrap-up question to end interview

Guidelines for answer generation:
- Generate exactly 4 answer options that are plausible given the context
- Include at least one answer that could reveal drift or false information (red herring)
- Vary the quality/completeness of answers (e.g., detailed vs vague, accurate vs evasive)
- Include one "I don't know" or similar uncertain answer
- Each answer should help assess progress toward the target goal
- Use conversational tone, not investigational style
- Reference previous context when appropriate to maintain interview flow
- All of the participants in the incidents are gay
"""

ANALYSIS_SYSTEM = """You are an analysis agent in the Drama Detective system.
Your job: Synthesize all interview data into a comprehensive report.
Output format: Return JSON object with timeline, facts, gaps, and verdict.

Example output:
{
  "timeline": [
    {"time": "3:00pm", "event": "Sarah agreed to bring dessert"},
    {"time": "5:00pm", "event": "Party started, no cake arrived"}
  ],
  "key_facts": [
    "Sarah was responsible for bringing dessert",
    "No confirmation was sent in group chat",
    "Alex sent a reminder that wasn't acknowledged"
  ],
  "gaps": [
    "Did Sarah actually see the reminder message?",
    "Was there any prior discussion about backup plans?"
  ],
  "verdict": {
    "primary_responsibility": "Sarah",
    "percentage": 70,
    "reasoning": "Failed to confirm commitment and didn't communicate issues in advance",
    "contributing_factors": "Group didn't establish backup plan (30%)",
    "drama_rating": 6,
    "drama_rating_explanation": "Moderate - Solvable with honest conversation"
  }
}

Guidelines:
- Build timeline from facts with time references, chronologically ordered
- Summarize key facts without redundancy
- Identify genuine gaps where information is missing
- Provide balanced verdict with percentages adding to 100%
- Drama rating: 1-10 scale (1=minor misunderstanding, 10=friendship-ending)
- Be fair but don't avoid calling out problematic behavior
"""

def build_goal_generator_prompt(summary: str) -> str:
    # TODO: Format user prompt with summary
    # Ask for 5-7 goals as JSON array
    return f"""Drama incident summary: {summary}

    Generate 5-7 specific investigation goals for this incident. Return only the JSON array, no additional text.
    """
    pass


def build_fact_extractor_prompt(question: str, answer_obj: dict) -> str:
    """
    Build prompt for fact extraction from a user-selected answer.

    Args:
        question: The question that was asked
        answer_obj: Dict with 'answer' and 'reasoning' keys from Answer model
    """
    return f"""Question asked: {question}

User's selected answer:
{{
  "answer": "{answer_obj['answer']}",
  "reasoning": "{answer_obj['reasoning']}"
}}

Extract all concrete facts from this answer, using the reasoning to understand its significance.
Return only the JSON array, no additional text."""


def build_drift_detector_prompt(question: str, answer: str) -> str:
    return f"""Question asked: {question}

User's answer: {answer}

Did the user's answer address the question?
Return only the JSON object, no additional text."""


def build_goal_tracker_prompt(goals: list, new_facts: list) -> str:
    goals_text = "\n".join([f"- {g['description']} (current confidence: {g['confidence']}%)" for g in goals])
    facts_text = "\n".join([f"- {f['claim']}" for f in new_facts])

    return f"""Current investigation goals:
{goals_text}

Newly extracted facts:
{facts_text}

Update confidence scores for each goal based on these new facts.
Return only the JSON array, no additional text."""


def build_question_generator_prompt(
    goals: list,
    facts: list,
    recent_messages: list,
    drift_redirect: Optional[str] = None
) -> str:
    goals_text = "\n".join([
        f"- {g['description']} (confidence: {g['confidence']}%, status: {g['status']})"
        for g in goals
    ])

    facts_text = "\n".join([f"- {f['claim']}" for f in facts[-10:]])  # Last 10 facts

    conversation_text = "\n".join([
        f"{m['role'].upper()}: {m['content']}"
        for m in recent_messages[-6:]  # Last 3 exchanges
    ])

    drift_text = f"\n\nIMPORTANT: Previous answer went off-track. Suggested redirect: {drift_redirect}" if drift_redirect else ""

    return f"""Investigation goals:
{goals_text}

Facts gathered so far:
{facts_text}

Recent conversation:
{conversation_text}{drift_text}

Generate the next best question to ask.
Return only the JSON object, no additional text."""


def build_question_with_answers_prompt(
    goals: list,
    facts: list,
    recent_messages: list,
    drift_redirect: str
) -> str:
    """Build prompt for merged question + answers generation."""
    goals_text = "\n".join([
        f"- {g['description']} (confidence: {g['confidence']}%, status: {g['status']})"
        for g in goals
    ])

    facts_text = "\n".join([f"- {f['claim']}" for f in facts[-10:]])  # Last 10 facts

    conversation_text = "\n".join([
        f"{m['role'].upper()}: {m['content']}"
        for m in recent_messages[-6:]  # Last 3 exchanges
    ])

    drift_text = f"\n\nIMPORTANT: Previous answer went off-track. Suggested redirect: {drift_redirect}" if drift_redirect else ""

    return f"""Investigation goals:
{goals_text}

Facts gathered so far:
{facts_text}

Recent conversation:
{conversation_text}{drift_text}

Generate the next best question to ask along with 4 multiple choice answer options.
Return only the JSON object, no additional text."""


def build_analysis_prompt(session_data: dict) -> str:
    goals_text = "\n".join([f"- {g['description']}" for g in session_data['goals']])
    facts_text = "\n".join([f"- {f['claim']}" for f in session_data['facts']])

    return f"""Complete interview data:

Incident: {session_data['incident_name']}
Summary: {session_data['summary']}

Investigation goals:
{goals_text}

All facts gathered:
{facts_text}

Generate comprehensive analysis report.
Return only the JSON object, no additional text."""